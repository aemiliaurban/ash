\chapter{Analysis of Flow Cytometry Data}
\label{chap:two}

\section{Introduction to Flow Cytometry}
\label{sec:introtoflow}
Flow cytometry is a high-throughput laboratory technique that allows for studying cellular populations, and is used for hypothesis testing as well as in the medical areas in both biomedical research and diagnostics, most importantly in clinical immunology. As described in \cite{black2011cell} , cell-based screening also allows for development of safer and more effective drugs. Flow cytometry can go trough thousands of samples a day.

The main goal of flow cytometry is to divide input cell population using various parameters, such as extracellular vesicles \citep{nolan2015flow}, membrane proteins \citep{schmitz2021bimolecular}, antibodies \citep{kalina2020relevance, hall1996use}, and intracellular particles \citep{pirone2021three, wronska2022intracellular}. It's even possible using it for measurements of molecular interactions such as ligand binding \citep{nolan1998emergence} or protein phosphorylation state \citep{perez2002simultaneous}.

Flow cytometry has facilitated access to new intracellular pathways, which were not revealed in other biochemical approaches \citep{sachs2005causal}.

It's been in development ever since its inception, and for years, it's been possible to make improvements remastering the main physical systems: fluidics, optics, and electronics, allowing for more precise measurements \citep{picot2012flow}. In it's core, it relies on optical methods, such as measuring light scattered from particles with noble gas lasers being the source of light, in the past, there were mostly argon-ion lasers \citep{kamentsky1991microscope}. Nowadays, cytometers take advantage of solid-state lasers. The advantage of lasers over different light sources is that the illumination point can easily be focused. The light scatters of individual cells flowing in a stream, targeting small sample volumes at a time, leading into sorting cells by size and complexity, cell cycle, or cell viability. Cells can be tagged with dyes or antibodies \citep{wilkerson2012principles}. The usage of multiple lasers is possible \citep{bigos1999nine, de2016quantification, ashcroft2000commercial}. A comprehensive overview of lasers in flow cytometry can be found in \cite{shapiro2018lasers}.

Commercially sold flow cytometers are either analysers or sorters. As the name suggests, sorters both collect data and sort cells by their properties. Flow cytometers can also be adjusted to specific use cases, such as the Ploidy Analyser manufactured by Partec, which is mainly useful in analysing plants as plants are regularly polyploid - meaning they have at least three complete sets of chromosomes \citep{zhang2003genetic, jacob1998pollen, geng2011genetic}. 

However, improvements such as the development of new fluorescent dyes led to increase in dataset size as more colors allow for tracking more parameters at a time - also known as polychromatic flow cytometry. as well as the number of not only intracellular parameters, producing rich information about individual cells \citep{wood20069}, that is impossible to process in traditional manual ways such as sequential manual gating, which is also observer-dependent and requires high specialization, often impacting results. It is also incredibly time consuming. The lack of fully functional automated tool hinders full potential of flow cytometry. 

To deal with the high-dimensional data and the issue of evergrowing time and space requirements, computer driven analytical techniques have been introduced, especially but not only from the area of hierarchical clustering as described in section \ref{sec:hierarchicalclustering}.

Methods that are reliant on prior knowledge of expected cell populations aka clusters \citep{lo2008automated, rogers2008cytometric, wilkins2001comparison, zeng2007feature} to deal with automatization and move the thing to the less observer-dependent manner are often. 

25/27

\section{Analysis}
\label{sec:analviagating}
Several methods of flow cytometry dataset analysis will be described in this section.
The analysis of data obtained from a flow cytometer can be done manually with all of its possible downfalls, or with the help of either commercially or freely available software. 

As with other types of workflows, quality assessment and control is essential. Through quality assessment, one can make sure that the differences among samples are biological, not technical. One of the approaches which can solve the issue is the development of graphical tools which can reveal non biological differences among samples \citep{le2007data}. Other methods suggested calibrating computation for each of the fluorescent parameters \citep{gratama1998flow}.

Sequential gating is useful for identification of specific populations, alas, it is limited in its visualization capabilities, as it can only take one as far as two parameters simultaneously. It is also prone to observer-dependent errors \citep{herzenberg2006interpreting}.

Automated gating difficulty increases with nonconvex cell populations, meaning populations that are neither concave nor convex but rather they curve up and down, or other multidimensional shapes, and can struggle with elliptical shapes that are often produced from flow cytometry \cite{finak2009merging}.
SPICE

Probability binning can help identify differences which are not visible through sequential manual gating by distributing the data into bins of same size, and compares the count of events between experimental sample and control. While historical methods that include Overton subtraction \citep{overton1988modified} or Komogorovs-Smirnoff statistic \citep{young1977proof} were useful, they suffered from enormous counts of bins. Probability binning works with minimizing the maximum expected variance by creating bins of various sizes. The smaller the bins, the more events, however, at the end, each bin no matter its size houses the same amount of events. It then compares the distributions, and does not require setting the expected number of cell populations from the beginning. One of its main advantages is that its computation time does not increase with scaling to more parameters. With quality assessment, it can escape one of its major downfalls, which is the sensitivity to variation in experimental conditions.
Frequency difference gating

Due to the nature of this thesis, cluster analysis is described in depth in \ref{sec:hierarchicalclustering}. 
One does not have to work with high dimensional data when they can get rid of the dimensions via principal component analysis. Principal component analysis is an unsupervised method of dimension-reduction, which works by creating a new dataset in which the new variables - principal components - are linear combinations of the original values. This allows for detecting patterns \citep{rauber2021cerebrospinal}.

Both principal component analysis and cluster analysis also has the advantage of being able to take fluorescent values individually and therefore account for individual variation.



